{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Trabalho.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asengardeon/imdb-sentimetal/blob/main/Trabalho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM_gEbjd6jWZ"
      },
      "source": [
        "**Instituição**: FURB  \n",
        "**Curso**: Data Science  \n",
        "**Disciplina**: Deep Learning  \n",
        "**Acadêmico**: Leandro Vilson Battisti  \n",
        "**Sobre**  \n",
        "O objetivo deste trabalho é criar um modelo binário de aprendizado de máquina para classificação de textos. Para isso, será utilizado a base de dados IMDB que consiste de dados textuais de críticas positivas e negativas de filmes."
      ],
      "id": "jM_gEbjd6jWZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94471057"
      },
      "source": [
        "### Classificação de textos para análise de sentimentos\n",
        "\n",
        "Base de dados \n",
        "\n",
        "Istruções:\n",
        "- O objetivo deste trabalho é criar um modelo binário de aprendizado de máquina para classificação de textos. \n",
        "Para isso, será utilizado a base de dados [IMDb](http://ai.stanford.edu/~amaas/data/sentiment/), que consiste de dados textuais de críticas positivas e negativas de filmes\n",
        "- Uma vez treinado, o modelo deve ter uma função `predict` que recebe uma string como parâmetro e retorna o valor 1 ou 0, aonde 1 significa uma crítica positiva e 0 uma crítica negativa\n",
        "- O pré-processamento pode ser desenvolvidado conforme desejar (ex.: remoção de stopwords, word embedding, one-hot encoding, char encoding)\n",
        "- É preferível que seja empregado um modelo de recorrência (ex.: rnn, lstm, gru) para a etapa de classificação\n",
        "- Documente o código (explique sucintamente o que cada função faz, insira comentários em trechos de código relevantes)\n",
        "- **Atenção**: Uma vez treinado o modelo final, salve-o no diretório do seu projeto e crie uma célula ao final do notebook contendo uma função de leitura deste arquivo, juntamente com a execução da função `predict`\n",
        "\n",
        "Sugestões:\n",
        "- Explorar a base de dados nas células iniciais do notebook para ter um melhor entendimento do problema, distribuição dos dados, etc\n",
        "- Após desenvolver a estrutura de classificação, é indicado fazer uma busca de hiperparâmetros e comparar os resultados obtidos em diferentes situações\n",
        "\n",
        "Prazo de entrega:\n",
        "- 01-08-2021 às 23:59hs GMT-3\n",
        "\n",
        "Formato preferível de entrega:\n",
        "- Postar no portal Ava da disciplina o link do projeto no github (ou anexar o projeto diretamente no portal Ava)\n",
        "\n",
        "luann.porfirio@gmail.com"
      ],
      "id": "94471057"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:36:57.559764Z",
          "start_time": "2021-06-10T00:36:52.638020Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2577de36",
        "outputId": "b37945c6-5473-4e0f-8a1a-b3a85da7f1ce"
      },
      "source": [
        "!pip install torchtext"
      ],
      "id": "2577de36",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:44:12.514627Z",
          "start_time": "2021-06-10T00:44:12.509125Z"
        },
        "id": "a80224ad"
      },
      "source": [
        "from torchtext import datasets\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch\n",
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset"
      ],
      "id": "a80224ad",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnx23fZp8Ei_"
      },
      "source": [
        ""
      ],
      "id": "Tnx23fZp8Ei_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:50:27.424355Z",
          "start_time": "2021-06-10T00:49:16.448387Z"
        },
        "id": "907e3626"
      },
      "source": [
        "train_iter, test_iter = datasets.IMDB()"
      ],
      "id": "907e3626",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnzH5x8QS2dA"
      },
      "source": [
        "#Definindo se roda em cpu ou gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "CnzH5x8QS2dA",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0LWMP3VRlYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c840421-45a7-41fd-df08-4f212cb9d0da"
      },
      "source": [
        "next(train_iter)\n"
      ],
      "id": "V0LWMP3VRlYj",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('neg',\n",
              " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpDUkDHSSJlR"
      },
      "source": [
        "#criação do tokenizador de texto e texto e criação do vocabularios base de avaliação do texto.\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "train_iter = datasets.IMDB(split='train')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "id": "gpDUkDHSSJlR",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvYrpZEf8Jn8"
      },
      "source": [
        ""
      ],
      "id": "XvYrpZEf8Jn8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAU8r9AFSYko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c14e313-e596-44f1-f00a-8ce1f73825c4"
      },
      "source": [
        "vocab(['here', 'is', 'an', 'example'])"
      ],
      "id": "lAU8r9AFSYko",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[131, 9, 40, 464]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWr-G7618-SH"
      },
      "source": [
        "###Estes pipelines são utilizados para tokenizar uma linha do dataloader  e para definir um código numerico para o sentimento referente a linha"
      ],
      "id": "DWr-G7618-SH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmBvbYgXSgSI"
      },
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: 0 if x == 'neg' else 1"
      ],
      "id": "cmBvbYgXSgSI",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2qSfjYn8xUR"
      },
      "source": [
        "### Antes de enviar para o modelo, a função collate_fn funciona em um lote de amostras geradas a partir do DataLoader. A entrada para collate_fn é um lote de dados com o tamanho do lote no DataLoader e collate_fn os processa de acordo com os pipelines de processamento de dados declarados anteriormente"
      ],
      "id": "q2qSfjYn8xUR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OE0qriwSoIx"
      },
      "source": [
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)"
      ],
      "id": "7OE0qriwSoIx",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTklr64_TEJo"
      },
      "source": [
        "train_iter = datasets.IMDB(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "id": "sTklr64_TEJo",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlajqKO59K0J"
      },
      "source": [
        "### Este é o modelo que irtemos utilizar. Um modelo de classificação de texto Linear"
      ],
      "id": "tlajqKO59K0J"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXe3yPUvTKl3"
      },
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        #utilizamo o Bag pois de forma resumida ele garante a estrutura necessária para textos de tamanhos diferentes além de melhorias de perforance\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "id": "TXe3yPUvTKl3",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N65YwAHV-V1j"
      },
      "source": [
        "Construímos um modelo com a dimensão de de interna de 64. O tamanho do vocabulário é igual ao comprimento da instância do vocabulário. O número de classes é igual ao número de rótulos, neste caso sendo 2 pois é positivo ou negativo, mas a implementação este flexivel para rótulos novos no futuro"
      ],
      "id": "N65YwAHV-V1j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMnIaAroTTUS"
      },
      "source": [
        "train_iter = datasets.IMDB(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "id": "YMnIaAroTTUS",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ-slDmOTjCT"
      },
      "source": [
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()        \n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()"
      ],
      "id": "yZ-slDmOTjCT",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKg9UoFYTkD5"
      },
      "source": [
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "id": "WKg9UoFYTkD5",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CSlROo1Tl5g"
      },
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n"
      ],
      "id": "7CSlROo1Tl5g",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqRD9acZTyqZ"
      },
      "source": [
        "train_iter, test_iter = datasets.IMDB()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)"
      ],
      "id": "AqRD9acZTyqZ",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akTAMlJiUIDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db28753-6373-48b7-a76b-8631bf8023da"
      },
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "id": "akTAMlJiUIDz",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  4.34s | valid accuracy    0.709 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  4.28s | valid accuracy    0.793 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  4.26s | valid accuracy    0.819 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  4.01s | valid accuracy    0.711 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  4.04s | valid accuracy    0.858 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  3.98s | valid accuracy    0.861 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  4.00s | valid accuracy    0.862 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  4.01s | valid accuracy    0.862 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  3.99s | valid accuracy    0.865 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  4.01s | valid accuracy    0.866 \n",
            "-----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NxX1yZzUMCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c60cadb-6adc-4c8b-dfdc-d25236c085cd"
      },
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "id": "_NxX1yZzUMCC",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqWZrv1GasQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3754fd23-218b-49d6-f1a7-ce0cbd5ce230"
      },
      "source": [
        "ag_news_label = {0: \"Negative\",\n",
        "                 1: \"Positive\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"A frantic and cold-to-the-touch film of anxious set pieces and paper-thin characters, “Jolt” tracks the misadventures of the abovementioned New Yorker, an unpredictably sturdy woman cursed with a rare neurological disorder that makes it impossible for her to manage her anger and control her violent impulses triggered by annoying strangers. Truth be told, some folks throughout the film—from frustrating man-spreaders on the subway to arrogant bigwigs rude to service staff—test one’s patience, and perhaps even deserve the kind bloody rage Lindy feels the urge to disseminate at various hours of any given day. But in order to function in a society and city where rudeness is often the norm or background noise at best, Lindy has no choice but indulge in the painful experimental treatment her mysterious, somewhat patronizing psychiatrist Dr. Munchin (Stanley Tucci) seems to have invented\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
      ],
      "id": "xqWZrv1GasQ7",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a Positive news\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}